{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# The modules we're going to use\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, convolutional, pooling, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# When you execute a code to plot with a simple SHIFT-ENTER, the plot will be shown directly under the code cell\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pre-processing, X_train size:  (16175, 2304)\n",
      "Before pre-processing, y_train size:  (16175,)\n",
      "Before pre-processing, X_test size:  (3965, 2304)\n",
      "After pre-processing, X_train size:  (16175, 1, 48, 48)\n",
      "After pre-processing, y_train size:  (16175, 3)\n",
      "After pre-processing, X_test size:  (3965, 1, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = np.genfromtxt('./train_data.csv',delimiter=',')\n",
    "train_targets = np.genfromtxt('./train_target.csv',delimiter=',')\n",
    "test_data = np.genfromtxt('./test_data.csv',delimiter=',')\n",
    "\n",
    "print('Before pre-processing, X_train size: ', train_data.shape)\n",
    "print('Before pre-processing, y_train size: ', train_targets.shape)\n",
    "print('Before pre-processing, X_test size: ', test_data.shape)\n",
    "\n",
    "train_data = train_data.reshape(-1,1, 48,48)\n",
    "test_data = test_data.reshape(-1,1, 48,48)\n",
    "\n",
    "train_targets = np_utils.to_categorical(train_targets, 3)\n",
    "\n",
    "print('After pre-processing, X_train size: ', train_data.shape)\n",
    "print('After pre-processing, y_train size: ', train_targets.shape)\n",
    "print('After pre-processing, X_test size: ', test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "drop_out_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "# model.add(pooling.MaxPooling2D(\n",
    "#     pool_size=(2, 2),\n",
    "#     padding='same',\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "# model.add(pooling.MaxPooling2D(\n",
    "#     pool_size=(2, 2),\n",
    "#     padding='same',\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(pooling.MaxPooling2D(\n",
    "#     pool_size=(2, 2),\n",
    "#     padding='same',\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "# model.add(pooling.MaxPooling2D(\n",
    "#     pool_size=(2, 2),\n",
    "#     padding='same',\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(pooling.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    padding='same',\n",
    "))\n",
    "\n",
    "############### END CONVOLUTIONAL LAYER (3) + MAX POOLING (1) ###############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "############### START FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "\n",
    "############### SECOND FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "\n",
    "############### THIRD FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "\n",
    "############### FOURTH FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "\n",
    "############### FOURTH FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "# model.add(Dense(500))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(drop_out_rate))\n",
    "\n",
    "############### FOURTH FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "# model.add(Dense(500))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(drop_out_rate))\n",
    "\n",
    "\n",
    "\n",
    "############### FIFTH FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "############### END FULLY CONNECTED LAYER ###############\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10513 samples, validate on 5662 samples\n",
      "Epoch 1/30\n",
      "10s - loss: 1.0686 - acc: 0.4429 - val_loss: 1.0653 - val_acc: 0.4465\n",
      "Epoch 2/30\n",
      "9s - loss: 1.0622 - acc: 0.4457 - val_loss: 1.0534 - val_acc: 0.4465\n",
      "Epoch 3/30\n",
      "9s - loss: 1.0391 - acc: 0.4554 - val_loss: 1.0278 - val_acc: 0.4763\n",
      "Epoch 4/30\n",
      "9s - loss: 1.0013 - acc: 0.5014 - val_loss: 1.0227 - val_acc: 0.4634\n",
      "Epoch 5/30\n",
      "9s - loss: 0.9813 - acc: 0.5228 - val_loss: 0.9919 - val_acc: 0.5113\n",
      "Epoch 6/30\n",
      "11s - loss: 0.9505 - acc: 0.5420 - val_loss: 0.9388 - val_acc: 0.5535\n",
      "Epoch 7/30\n",
      "10s - loss: 0.9409 - acc: 0.5538 - val_loss: 0.9231 - val_acc: 0.5634\n",
      "Epoch 8/30\n",
      "11s - loss: 0.9208 - acc: 0.5616 - val_loss: 0.9206 - val_acc: 0.5777\n",
      "Epoch 9/30\n",
      "9s - loss: 0.8983 - acc: 0.5774 - val_loss: 0.8935 - val_acc: 0.5911\n",
      "Epoch 10/30\n",
      "9s - loss: 0.8863 - acc: 0.5910 - val_loss: 0.8956 - val_acc: 0.5842\n",
      "Epoch 11/30\n",
      "9s - loss: 0.8776 - acc: 0.5944 - val_loss: 0.8951 - val_acc: 0.5841\n",
      "Epoch 12/30\n",
      "8s - loss: 0.8632 - acc: 0.6033 - val_loss: 0.8745 - val_acc: 0.6016\n",
      "Epoch 13/30\n",
      "9s - loss: 0.8394 - acc: 0.6232 - val_loss: 0.8690 - val_acc: 0.6058\n",
      "Epoch 14/30\n",
      "9s - loss: 0.8322 - acc: 0.6270 - val_loss: 0.8626 - val_acc: 0.6146\n",
      "Epoch 15/30\n",
      "10s - loss: 0.8107 - acc: 0.6353 - val_loss: 0.8535 - val_acc: 0.6065\n",
      "Epoch 16/30\n",
      "10s - loss: 0.8033 - acc: 0.6412 - val_loss: 0.8646 - val_acc: 0.6058\n",
      "Epoch 17/30\n",
      "10s - loss: 0.7969 - acc: 0.6405 - val_loss: 0.8603 - val_acc: 0.6129\n",
      "Epoch 18/30\n",
      "9s - loss: 0.7721 - acc: 0.6575 - val_loss: 0.8373 - val_acc: 0.6268\n",
      "Epoch 19/30\n",
      "9s - loss: 0.7539 - acc: 0.6702 - val_loss: 0.8478 - val_acc: 0.6205\n",
      "Epoch 20/30\n",
      "10s - loss: 0.7587 - acc: 0.6624 - val_loss: 0.8510 - val_acc: 0.6196\n",
      "Epoch 21/30\n",
      "10s - loss: 0.7398 - acc: 0.6750 - val_loss: 0.8480 - val_acc: 0.6155\n",
      "Epoch 22/30\n",
      "9s - loss: 0.7310 - acc: 0.6777 - val_loss: 0.8501 - val_acc: 0.6164\n",
      "Epoch 23/30\n",
      "9s - loss: 0.7072 - acc: 0.6914 - val_loss: 0.8584 - val_acc: 0.6261\n",
      "Epoch 24/30\n",
      "9s - loss: 0.6756 - acc: 0.7099 - val_loss: 0.8647 - val_acc: 0.6282\n",
      "Epoch 25/30\n",
      "9s - loss: 0.6688 - acc: 0.7111 - val_loss: 0.8536 - val_acc: 0.6240\n",
      "Epoch 26/30\n",
      "8s - loss: 0.6637 - acc: 0.7177 - val_loss: 0.8568 - val_acc: 0.6252\n",
      "Epoch 27/30\n",
      "10s - loss: 0.6508 - acc: 0.7225 - val_loss: 0.8944 - val_acc: 0.6176\n",
      "Epoch 28/30\n",
      "10s - loss: 0.6145 - acc: 0.7415 - val_loss: 0.9109 - val_acc: 0.6123\n",
      "Epoch 29/30\n",
      "10s - loss: 0.6021 - acc: 0.7476 - val_loss: 0.9151 - val_acc: 0.6159\n",
      "Epoch 30/30\n",
      "12s - loss: 0.5956 - acc: 0.7521 - val_loss: 0.9373 - val_acc: 0.6160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3194a13be0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(\n",
    "    # optimizer = adam,\n",
    "    optimizer = 'adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# model.fit(train_data, train_targets,epochs=10,batch_size=32,verbose=2)\n",
    "model.fit(train_data, train_targets, validation_split=0.35, epochs=30, batch_size=512, verbose=2)\n",
    "\n",
    "# loss, accuracy = model.evaluate(test_data, test_target, verbose=2)\n",
    "# print('test loss:', loss)\n",
    "# print('test accuracy', accuracy)\n",
    "\n",
    "\n",
    "# output = model.predict(X_test[temp[0]].reshape(-1,1, 28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
