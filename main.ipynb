{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# The modules we're going to use\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, convolutional, pooling, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# When you execute a code to plot with a simple SHIFT-ENTER, the plot will be shown directly under the code cell\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pre-processing, X_train size:  (16175, 2304)\n",
      "Before pre-processing, y_train size:  (16175,)\n",
      "Before pre-processing, X_test size:  (3965, 2304)\n",
      "After pre-processing, X_train size:  (16175, 1, 48, 48)\n",
      "After pre-processing, y_train size:  (16175, 3)\n",
      "After pre-processing, X_test size:  (3965, 1, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = np.genfromtxt('./train_data.csv',delimiter=',')\n",
    "train_targets = np.genfromtxt('./train_target.csv',delimiter=',')\n",
    "test_data = np.genfromtxt('./test_data.csv',delimiter=',')\n",
    "\n",
    "print('Before pre-processing, X_train size: ', train_data.shape)\n",
    "print('Before pre-processing, y_train size: ', train_targets.shape)\n",
    "print('Before pre-processing, X_test size: ', test_data.shape)\n",
    "\n",
    "train_data = train_data.reshape(-1,1, 48,48)\n",
    "test_data = test_data.reshape(-1,1, 48,48)\n",
    "\n",
    "train_targets = np_utils.to_categorical(train_targets, 3)\n",
    "\n",
    "print('After pre-processing, X_train size: ', train_data.shape)\n",
    "print('After pre-processing, y_train size: ', train_targets.shape)\n",
    "print('After pre-processing, X_test size: ', test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "drop_out_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "# model.add(pooling.MaxPooling2D(\n",
    "#     pool_size=(2, 2),\n",
    "#     padding='same',\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "# model.add(pooling.MaxPooling2D(\n",
    "#     pool_size=(2, 2),\n",
    "#     padding='same',\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(pooling.MaxPooling2D(\n",
    "#     pool_size=(2, 2),\n",
    "#     padding='same',\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "# model.add(pooling.MaxPooling2D(\n",
    "#     pool_size=(2, 2),\n",
    "#     padding='same',\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    # input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(pooling.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    padding='same',\n",
    "))\n",
    "\n",
    "############### END CONVOLUTIONAL LAYER (3) + MAX POOLING (1) ###############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "############### START FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "\n",
    "############### SECOND FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "\n",
    "############### THIRD FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "\n",
    "############### FOURTH FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "\n",
    "############### FOURTH FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "# model.add(Dense(500))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(drop_out_rate))\n",
    "\n",
    "############### FOURTH FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "# model.add(Dense(500))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(drop_out_rate))\n",
    "\n",
    "\n",
    "\n",
    "############### FIFTH FIRST FULLY CONNECTED LAYER ###############\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "############### END FULLY CONNECTED LAYER ###############\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12940 samples, validate on 3235 samples\n",
      "Epoch 1/70\n",
      "11s - loss: 0.6765 - acc: 0.7202 - val_loss: 0.8659 - val_acc: 0.6226\n",
      "Epoch 2/70\n",
      "10s - loss: 0.6159 - acc: 0.7440 - val_loss: 0.8590 - val_acc: 0.6365\n",
      "Epoch 3/70\n",
      "10s - loss: 0.5832 - acc: 0.7649 - val_loss: 0.8838 - val_acc: 0.6219\n",
      "Epoch 4/70\n",
      "11s - loss: 0.5641 - acc: 0.7713 - val_loss: 0.9062 - val_acc: 0.6266\n",
      "Epoch 5/70\n",
      "10s - loss: 0.5401 - acc: 0.7853 - val_loss: 0.9055 - val_acc: 0.6244\n",
      "Epoch 6/70\n",
      "9s - loss: 0.5309 - acc: 0.7916 - val_loss: 0.9442 - val_acc: 0.6155\n",
      "Epoch 7/70\n",
      "10s - loss: 0.5222 - acc: 0.7917 - val_loss: 0.9247 - val_acc: 0.6219\n",
      "Epoch 8/70\n",
      "9s - loss: 0.5071 - acc: 0.7986 - val_loss: 0.9663 - val_acc: 0.6244\n",
      "Epoch 9/70\n",
      "9s - loss: 0.4950 - acc: 0.8063 - val_loss: 0.9481 - val_acc: 0.6291\n",
      "Epoch 10/70\n",
      "8s - loss: 0.4925 - acc: 0.8057 - val_loss: 0.9647 - val_acc: 0.6176\n",
      "Epoch 11/70\n",
      "9s - loss: 0.4926 - acc: 0.8042 - val_loss: 0.9744 - val_acc: 0.6219\n",
      "Epoch 12/70\n",
      "9s - loss: 0.4524 - acc: 0.8248 - val_loss: 1.0059 - val_acc: 0.6148\n",
      "Epoch 13/70\n",
      "9s - loss: 0.4581 - acc: 0.8178 - val_loss: 0.9966 - val_acc: 0.6257\n",
      "Epoch 14/70\n",
      "9s - loss: 0.4247 - acc: 0.8334 - val_loss: 1.0205 - val_acc: 0.6247\n",
      "Epoch 15/70\n",
      "9s - loss: 0.4104 - acc: 0.8389 - val_loss: 1.0323 - val_acc: 0.6229\n",
      "Epoch 16/70\n",
      "9s - loss: 0.4009 - acc: 0.8474 - val_loss: 1.0590 - val_acc: 0.6198\n",
      "Epoch 17/70\n",
      "9s - loss: 0.3948 - acc: 0.8505 - val_loss: 1.0547 - val_acc: 0.6114\n",
      "Epoch 18/70\n",
      "8s - loss: 0.3796 - acc: 0.8548 - val_loss: 1.1400 - val_acc: 0.6198\n",
      "Epoch 19/70\n",
      "9s - loss: 0.3881 - acc: 0.8516 - val_loss: 1.0731 - val_acc: 0.6210\n",
      "Epoch 20/70\n",
      "9s - loss: 0.3765 - acc: 0.8495 - val_loss: 1.0713 - val_acc: 0.6192\n",
      "Epoch 21/70\n",
      "9s - loss: 0.3547 - acc: 0.8644 - val_loss: 1.1649 - val_acc: 0.6133\n",
      "Epoch 22/70\n",
      "9s - loss: 0.3458 - acc: 0.8636 - val_loss: 1.1360 - val_acc: 0.6111\n",
      "Epoch 23/70\n",
      "9s - loss: 0.3357 - acc: 0.8734 - val_loss: 1.1564 - val_acc: 0.6179\n",
      "Epoch 24/70\n",
      "9s - loss: 0.3281 - acc: 0.8744 - val_loss: 1.1555 - val_acc: 0.6093\n",
      "Epoch 25/70\n",
      "8s - loss: 0.3211 - acc: 0.8777 - val_loss: 1.1972 - val_acc: 0.6213\n",
      "Epoch 26/70\n",
      "9s - loss: 0.3091 - acc: 0.8828 - val_loss: 1.2103 - val_acc: 0.6161\n",
      "Epoch 27/70\n",
      "9s - loss: 0.3039 - acc: 0.8808 - val_loss: 1.1975 - val_acc: 0.6155\n",
      "Epoch 28/70\n",
      "9s - loss: 0.3077 - acc: 0.8823 - val_loss: 1.1974 - val_acc: 0.6232\n",
      "Epoch 29/70\n",
      "9s - loss: 0.2899 - acc: 0.8897 - val_loss: 1.2998 - val_acc: 0.6037\n",
      "Epoch 30/70\n",
      "9s - loss: 0.2817 - acc: 0.8892 - val_loss: 1.2930 - val_acc: 0.6025\n",
      "Epoch 31/70\n",
      "9s - loss: 0.2857 - acc: 0.8895 - val_loss: 1.2899 - val_acc: 0.6167\n",
      "Epoch 32/70\n",
      "10s - loss: 0.2629 - acc: 0.9032 - val_loss: 1.3569 - val_acc: 0.6142\n",
      "Epoch 33/70\n",
      "8s - loss: 0.2843 - acc: 0.8877 - val_loss: 1.2820 - val_acc: 0.6192\n",
      "Epoch 34/70\n",
      "14s - loss: 0.2911 - acc: 0.8901 - val_loss: 1.2854 - val_acc: 0.6087\n",
      "Epoch 35/70\n",
      "18s - loss: 0.2694 - acc: 0.8985 - val_loss: 1.3427 - val_acc: 0.6195\n",
      "Epoch 36/70\n",
      "11s - loss: 0.2378 - acc: 0.9111 - val_loss: 1.3927 - val_acc: 0.6124\n",
      "Epoch 37/70\n",
      "10s - loss: 0.2332 - acc: 0.9122 - val_loss: 1.3755 - val_acc: 0.6121\n",
      "Epoch 38/70\n",
      "10s - loss: 0.2421 - acc: 0.9073 - val_loss: 1.3660 - val_acc: 0.6053\n",
      "Epoch 39/70\n",
      "6s - loss: 0.2273 - acc: 0.9144 - val_loss: 1.4350 - val_acc: 0.6133\n",
      "Epoch 40/70\n",
      "6s - loss: 0.2238 - acc: 0.9147 - val_loss: 1.4115 - val_acc: 0.6136\n",
      "Epoch 41/70\n",
      "6s - loss: 0.2270 - acc: 0.9124 - val_loss: 1.4423 - val_acc: 0.6096\n",
      "Epoch 42/70\n",
      "5s - loss: 0.2142 - acc: 0.9185 - val_loss: 1.5302 - val_acc: 0.6136\n",
      "Epoch 43/70\n",
      "5s - loss: 0.2160 - acc: 0.9208 - val_loss: 1.5033 - val_acc: 0.6087\n",
      "Epoch 44/70\n",
      "5s - loss: 0.2126 - acc: 0.9189 - val_loss: 1.4397 - val_acc: 0.6090\n",
      "Epoch 45/70\n",
      "5s - loss: 0.1990 - acc: 0.9236 - val_loss: 1.5823 - val_acc: 0.6015\n",
      "Epoch 46/70\n",
      "5s - loss: 0.2107 - acc: 0.9221 - val_loss: 1.4897 - val_acc: 0.6155\n",
      "Epoch 47/70\n",
      "5s - loss: 0.2192 - acc: 0.9188 - val_loss: 1.4210 - val_acc: 0.6151\n",
      "Epoch 48/70\n",
      "5s - loss: 0.2012 - acc: 0.9246 - val_loss: 1.4844 - val_acc: 0.6124\n",
      "Epoch 49/70\n",
      "5s - loss: 0.1888 - acc: 0.9274 - val_loss: 1.5988 - val_acc: 0.6053\n",
      "Epoch 50/70\n",
      "4s - loss: 0.1868 - acc: 0.9285 - val_loss: 1.5318 - val_acc: 0.6127\n",
      "Epoch 51/70\n",
      "5s - loss: 0.1796 - acc: 0.9329 - val_loss: 1.6153 - val_acc: 0.6080\n",
      "Epoch 52/70\n",
      "4s - loss: 0.1843 - acc: 0.9295 - val_loss: 1.6013 - val_acc: 0.6080\n",
      "Epoch 53/70\n",
      "6s - loss: 0.1917 - acc: 0.9286 - val_loss: 1.5247 - val_acc: 0.6090\n",
      "Epoch 54/70\n",
      "7s - loss: 0.1656 - acc: 0.9369 - val_loss: 1.6671 - val_acc: 0.6114\n",
      "Epoch 55/70\n",
      "7s - loss: 0.1862 - acc: 0.9305 - val_loss: 1.5528 - val_acc: 0.6213\n",
      "Epoch 56/70\n",
      "7s - loss: 0.1867 - acc: 0.9284 - val_loss: 1.6047 - val_acc: 0.6111\n",
      "Epoch 57/70\n",
      "7s - loss: 0.1694 - acc: 0.9369 - val_loss: 1.6841 - val_acc: 0.6099\n",
      "Epoch 58/70\n",
      "6s - loss: 0.1683 - acc: 0.9364 - val_loss: 1.6904 - val_acc: 0.6151\n",
      "Epoch 59/70\n",
      "5s - loss: 0.1867 - acc: 0.9291 - val_loss: 1.6146 - val_acc: 0.6142\n",
      "Epoch 60/70\n",
      "5s - loss: 0.1557 - acc: 0.9423 - val_loss: 1.7259 - val_acc: 0.6148\n",
      "Epoch 61/70\n",
      "6s - loss: 0.1567 - acc: 0.9382 - val_loss: 1.7442 - val_acc: 0.6009\n",
      "Epoch 62/70\n",
      "6s - loss: 0.1629 - acc: 0.9392 - val_loss: 1.6084 - val_acc: 0.6096\n",
      "Epoch 63/70\n",
      "5s - loss: 0.1533 - acc: 0.9431 - val_loss: 1.6910 - val_acc: 0.6065\n",
      "Epoch 64/70\n",
      "5s - loss: 0.1612 - acc: 0.9403 - val_loss: 1.7142 - val_acc: 0.6083\n",
      "Epoch 65/70\n",
      "5s - loss: 0.1605 - acc: 0.9409 - val_loss: 1.6858 - val_acc: 0.6093\n",
      "Epoch 66/70\n",
      "4s - loss: 0.1455 - acc: 0.9469 - val_loss: 1.7147 - val_acc: 0.6136\n",
      "Epoch 67/70\n",
      "5s - loss: 0.1515 - acc: 0.9434 - val_loss: 1.7105 - val_acc: 0.6049\n",
      "Epoch 68/70\n",
      "4s - loss: 0.1462 - acc: 0.9472 - val_loss: 1.7291 - val_acc: 0.6117\n",
      "Epoch 69/70\n",
      "5s - loss: 0.1507 - acc: 0.9444 - val_loss: 1.6857 - val_acc: 0.6161\n",
      "Epoch 70/70\n",
      "4s - loss: 0.1466 - acc: 0.9456 - val_loss: 1.7173 - val_acc: 0.6121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3171b34630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(\n",
    "    # optimizer = adam,\n",
    "    optimizer = 'adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# model.fit(train_data, train_targets,epochs=10,batch_size=32,verbose=2)\n",
    "model.fit(train_data, train_targets, validation_split=0.20, epochs=70, batch_size=1024, verbose=2)\n",
    "\n",
    "# loss, accuracy = model.evaluate(test_data, test_target, verbose=2)\n",
    "# print('test loss:', loss)\n",
    "# print('test accuracy', accuracy)\n",
    "\n",
    "\n",
    "# output = model.predict(X_test[temp[0]].reshape(-1,1, 28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
