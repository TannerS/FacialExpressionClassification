{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# The modules we're going to use\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, convolutional, pooling, Flatten, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pre-processing, X_train size:  (11322, 2304)\n",
      "Before pre-processing, y_train size:  (11322, 1)\n",
      "Before pre-processing, X_test size:  (3965, 2304)\n",
      "Before pre-processing, X_val size:  (4853, 2304)\n",
      "Before pre-processing, y_val size:  (4853, 1)\n",
      "After pre-processing, X_train size:  (11322, 1, 48, 48)\n",
      "After pre-processing, y_train size:  (11322, 3)\n",
      "After pre-processing, X_test size:  (3965, 1, 48, 48)\n",
      "After pre-processing, X_val size:  (4853, 1, 48, 48)\n",
      "After pre-processing, y_val size:  (4853, 3)\n"
     ]
    }
   ],
   "source": [
    "# load the training and target data from the data set (which is csv)\n",
    "train_data = np.genfromtxt('./train_data.csv',delimiter=',')\n",
    "train_target = np.genfromtxt('./train_target.csv', delimiter=',')\n",
    "# load the test data also\n",
    "test_data = np.genfromtxt('./test_data.csv',delimiter=',')\n",
    "# here we split the training data to get some data for cross validation\n",
    "train_data, val_data, train_target, val_target = train_test_split(train_data, (train_target[:, np.newaxis]), test_size=0.3, random_state=42)\n",
    "# display dataset shapes before processing\n",
    "print('Before pre-processing, X_train size: ', train_data.shape)\n",
    "print('Before pre-processing, y_train size: ', train_target.shape)\n",
    "print('Before pre-processing, X_test size: ', test_data.shape)\n",
    "print('Before pre-processing, X_val size: ', val_data.shape)\n",
    "print('Before pre-processing, y_val size: ', val_target.shape)\n",
    "# reshape the data to match the pixles of the image (-1, = stays same, 1 = 1 channel, 48 & 48means 48x48 image)\n",
    "train_data = train_data.reshape(-1,1, 48,48)\n",
    "test_data = test_data.reshape(-1,1, 48,48)\n",
    "val_data = val_data.reshape(-1,1, 48,48)\n",
    "# break down the targets into forms of 0,1, or 2\n",
    "train_target = np_utils.to_categorical(train_target, 3)\n",
    "val_target = np_utils.to_categorical(val_target, 3)\n",
    "# display the new shapes\n",
    "print('After pre-processing, X_train size: ', train_data.shape)\n",
    "print('After pre-processing, y_train size: ', train_target.shape)\n",
    "print('After pre-processing, X_test size: ', test_data.shape)\n",
    "print('After pre-processing, X_val size: ', val_data.shape)\n",
    "print('After pre-processing, y_val size: ', val_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new model\n",
    "model = Sequential()\n",
    "# create a convolutional layer for 2 dimensions\n",
    "# this one includes the input size ofr first layer\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=(2, 2),\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    input_shape=train_data.shape[1:],\n",
    "    activation='relu'\n",
    "))\n",
    "# create a convolutional layer for 2 dimensions\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=(2, 2),\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    activation='relu'\n",
    "))\n",
    "# create a convolutional layer for 2 dimensions\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=(2, 2),\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    activation='relu'\n",
    "))\n",
    "\n",
    "#Added a drop out of 10%\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# create a max pooling layer for 2 dimensions\n",
    "model.add(pooling.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    padding='same',\n",
    "))\n",
    "# create a convolutional layer for 2 dimensions\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(2, 2),\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    activation='relu'\n",
    "))\n",
    "# create a convolutional layer for 2 dimensions\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(2, 2),\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    activation='relu'\n",
    "))\n",
    "# create a convolutional layer for 2 dimensions\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(2, 2),\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    activation='relu'\n",
    "))\n",
    "#Added a drop out of 10%\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# create a max pooling layer for 2 dimensions\n",
    "model.add(pooling.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    padding='same',\n",
    "))\n",
    "# create a convolutional layer for 2 dimensions\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=128,\n",
    "    kernel_size=(2, 2),\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    activation='relu'\n",
    "))\n",
    "# create a convolutional layer for 2 dimensions\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=128,\n",
    "    kernel_size=(2, 2),\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    activation='relu'\n",
    "))\n",
    "# create a convolutional layer for 2 dimensions\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=128,\n",
    "    kernel_size=(2, 2),\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    activation='relu'\n",
    "))\n",
    "#Added a drop out of 10%\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "\n",
    "# create a max pooling layer for 2 dimensions\n",
    "model.add(pooling.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    padding='same',\n",
    "))\n",
    "# flatten the model's layer into a deep neuron which in turn, will be part of the fully connected feedforward network\n",
    "model.add(Flatten())\n",
    "# create dorpout layer to help with overfitting\n",
    "model.add(Dropout(.5))\n",
    "# create a single deep layer with a depth of 1024 for the output space\n",
    "model.add(Dense(1024))\n",
    "# choosing this as the activation type\n",
    "model.add(Activation('relu'))\n",
    "# create dorpout layer to help with overfitting\n",
    "model.add(Dropout(.2))\n",
    "# last layer is the softmax layer to get the probability of each class\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11322 samples, validate on 4853 samples\n",
      "Epoch 1/150\n",
      "26s - loss: 1.0715 - acc: 0.4393 - val_loss: 1.0566 - val_acc: 0.4548\n",
      "Epoch 2/150\n",
      "25s - loss: 1.0505 - acc: 0.4615 - val_loss: 1.0248 - val_acc: 0.5001\n",
      "Epoch 3/150\n",
      "25s - loss: 1.0178 - acc: 0.4960 - val_loss: 1.0393 - val_acc: 0.5098\n",
      "Epoch 4/150\n",
      "25s - loss: 0.9810 - acc: 0.5226 - val_loss: 0.9626 - val_acc: 0.5588\n",
      "Epoch 5/150\n",
      "25s - loss: 0.9539 - acc: 0.5455 - val_loss: 0.9302 - val_acc: 0.5675\n",
      "Epoch 6/150\n",
      "26s - loss: 0.9258 - acc: 0.5654 - val_loss: 0.9018 - val_acc: 0.5747\n",
      "Epoch 7/150\n",
      "25s - loss: 0.9132 - acc: 0.5701 - val_loss: 0.9056 - val_acc: 0.5708\n",
      "Epoch 8/150\n",
      "25s - loss: 0.8942 - acc: 0.5816 - val_loss: 0.8899 - val_acc: 0.5994\n",
      "Epoch 9/150\n",
      "25s - loss: 0.8793 - acc: 0.5927 - val_loss: 0.8881 - val_acc: 0.5852\n",
      "Epoch 10/150\n",
      "27s - loss: 0.8749 - acc: 0.5942 - val_loss: 0.8656 - val_acc: 0.5974\n",
      "Epoch 11/150\n",
      "25s - loss: 0.8627 - acc: 0.5984 - val_loss: 0.8720 - val_acc: 0.6031\n",
      "Epoch 12/150\n",
      "28s - loss: 0.8547 - acc: 0.6064 - val_loss: 0.8746 - val_acc: 0.5912\n",
      "Epoch 13/150\n",
      "27s - loss: 0.8391 - acc: 0.6170 - val_loss: 0.8571 - val_acc: 0.6058\n",
      "Epoch 14/150\n",
      "28s - loss: 0.8364 - acc: 0.6174 - val_loss: 0.8558 - val_acc: 0.5949\n",
      "Epoch 15/150\n",
      "28s - loss: 0.8300 - acc: 0.6189 - val_loss: 0.8422 - val_acc: 0.6124\n",
      "Epoch 16/150\n",
      "27s - loss: 0.8083 - acc: 0.6331 - val_loss: 0.8387 - val_acc: 0.6099\n",
      "Epoch 17/150\n",
      "27s - loss: 0.8073 - acc: 0.6340 - val_loss: 0.8379 - val_acc: 0.6209\n",
      "Epoch 18/150\n",
      "27s - loss: 0.7959 - acc: 0.6410 - val_loss: 0.8431 - val_acc: 0.6106\n",
      "Epoch 19/150\n",
      "27s - loss: 0.7855 - acc: 0.6462 - val_loss: 0.8308 - val_acc: 0.6163\n",
      "Epoch 20/150\n",
      "28s - loss: 0.7824 - acc: 0.6463 - val_loss: 0.8348 - val_acc: 0.6147\n",
      "Epoch 21/150\n",
      "25s - loss: 0.7781 - acc: 0.6477 - val_loss: 0.8310 - val_acc: 0.6198\n",
      "Epoch 22/150\n",
      "25s - loss: 0.7699 - acc: 0.6519 - val_loss: 0.8148 - val_acc: 0.6326\n",
      "Epoch 23/150\n",
      "25s - loss: 0.7579 - acc: 0.6581 - val_loss: 0.8265 - val_acc: 0.6338\n",
      "Epoch 24/150\n",
      "26s - loss: 0.7521 - acc: 0.6664 - val_loss: 0.8127 - val_acc: 0.6326\n",
      "Epoch 25/150\n",
      "25s - loss: 0.7517 - acc: 0.6597 - val_loss: 0.8423 - val_acc: 0.6070\n",
      "Epoch 26/150\n",
      "25s - loss: 0.7404 - acc: 0.6666 - val_loss: 0.8322 - val_acc: 0.6235\n",
      "Epoch 27/150\n",
      "26s - loss: 0.7430 - acc: 0.6734 - val_loss: 0.8115 - val_acc: 0.6336\n",
      "Epoch 28/150\n",
      "26s - loss: 0.7209 - acc: 0.6817 - val_loss: 0.8103 - val_acc: 0.6316\n",
      "Epoch 29/150\n",
      "25s - loss: 0.7209 - acc: 0.6809 - val_loss: 0.8077 - val_acc: 0.6328\n",
      "Epoch 30/150\n",
      "25s - loss: 0.7091 - acc: 0.6848 - val_loss: 0.8170 - val_acc: 0.6268\n",
      "Epoch 31/150\n",
      "25s - loss: 0.7126 - acc: 0.6857 - val_loss: 0.8082 - val_acc: 0.6324\n",
      "Epoch 32/150\n",
      "26s - loss: 0.6951 - acc: 0.6966 - val_loss: 0.8264 - val_acc: 0.6309\n",
      "Epoch 33/150\n",
      "25s - loss: 0.6951 - acc: 0.6914 - val_loss: 0.8151 - val_acc: 0.6423\n",
      "Epoch 34/150\n",
      "26s - loss: 0.6839 - acc: 0.7020 - val_loss: 0.8359 - val_acc: 0.6266\n",
      "Epoch 35/150\n",
      "25s - loss: 0.6830 - acc: 0.6997 - val_loss: 0.8055 - val_acc: 0.6408\n",
      "Epoch 36/150\n",
      "25s - loss: 0.6737 - acc: 0.7030 - val_loss: 0.8188 - val_acc: 0.6233\n",
      "Epoch 37/150\n",
      "26s - loss: 0.6676 - acc: 0.7079 - val_loss: 0.8198 - val_acc: 0.6314\n",
      "Epoch 38/150\n",
      "25s - loss: 0.6672 - acc: 0.7075 - val_loss: 0.8123 - val_acc: 0.6439\n",
      "Epoch 39/150\n",
      "25s - loss: 0.6611 - acc: 0.7130 - val_loss: 0.8304 - val_acc: 0.6285\n",
      "Epoch 40/150\n",
      "25s - loss: 0.6519 - acc: 0.7157 - val_loss: 0.8141 - val_acc: 0.6316\n",
      "Epoch 41/150\n",
      "26s - loss: 0.6426 - acc: 0.7209 - val_loss: 0.8155 - val_acc: 0.6349\n",
      "Epoch 42/150\n",
      "26s - loss: 0.6433 - acc: 0.7216 - val_loss: 0.8296 - val_acc: 0.6380\n",
      "Epoch 43/150\n",
      "25s - loss: 0.6391 - acc: 0.7234 - val_loss: 0.8312 - val_acc: 0.6375\n",
      "Epoch 44/150\n",
      "30s - loss: 0.6309 - acc: 0.7271 - val_loss: 0.8210 - val_acc: 0.6413\n",
      "Epoch 45/150\n",
      "24s - loss: 0.6190 - acc: 0.7311 - val_loss: 0.8258 - val_acc: 0.6347\n",
      "Epoch 46/150\n",
      "26s - loss: 0.6171 - acc: 0.7341 - val_loss: 0.8074 - val_acc: 0.6481\n",
      "Epoch 47/150\n",
      "25s - loss: 0.6102 - acc: 0.7409 - val_loss: 0.8282 - val_acc: 0.6394\n",
      "Epoch 48/150\n",
      "24s - loss: 0.6057 - acc: 0.7419 - val_loss: 0.8280 - val_acc: 0.6448\n",
      "Epoch 49/150\n",
      "24s - loss: 0.6200 - acc: 0.7318 - val_loss: 0.8175 - val_acc: 0.6417\n",
      "Epoch 50/150\n",
      "24s - loss: 0.5900 - acc: 0.7493 - val_loss: 0.8317 - val_acc: 0.6380\n",
      "Epoch 51/150\n",
      "25s - loss: 0.5924 - acc: 0.7471 - val_loss: 0.8403 - val_acc: 0.6402\n",
      "Epoch 52/150\n",
      "25s - loss: 0.5895 - acc: 0.7486 - val_loss: 0.8481 - val_acc: 0.6318\n",
      "Epoch 53/150\n",
      "24s - loss: 0.5912 - acc: 0.7443 - val_loss: 0.8245 - val_acc: 0.6410\n",
      "Epoch 54/150\n",
      "25s - loss: 0.5776 - acc: 0.7502 - val_loss: 0.8446 - val_acc: 0.6394\n",
      "Epoch 55/150\n",
      "24s - loss: 0.5644 - acc: 0.7568 - val_loss: 0.8337 - val_acc: 0.6468\n",
      "Epoch 56/150\n",
      "24s - loss: 0.5575 - acc: 0.7635 - val_loss: 0.8328 - val_acc: 0.6309\n",
      "Epoch 57/150\n",
      "25s - loss: 0.5491 - acc: 0.7674 - val_loss: 0.8506 - val_acc: 0.6318\n",
      "Epoch 58/150\n",
      "24s - loss: 0.5524 - acc: 0.7644 - val_loss: 0.8592 - val_acc: 0.6295\n",
      "Epoch 59/150\n",
      "25s - loss: 0.5559 - acc: 0.7596 - val_loss: 0.8715 - val_acc: 0.6345\n",
      "Epoch 60/150\n",
      "25s - loss: 0.5355 - acc: 0.7756 - val_loss: 0.8464 - val_acc: 0.6396\n",
      "Epoch 61/150\n",
      "25s - loss: 0.5417 - acc: 0.7727 - val_loss: 0.8409 - val_acc: 0.6382\n",
      "Epoch 62/150\n",
      "24s - loss: 0.5305 - acc: 0.7778 - val_loss: 0.8548 - val_acc: 0.6322\n",
      "Epoch 63/150\n",
      "24s - loss: 0.5269 - acc: 0.7806 - val_loss: 0.8875 - val_acc: 0.6384\n",
      "Epoch 64/150\n",
      "24s - loss: 0.5109 - acc: 0.7877 - val_loss: 0.8568 - val_acc: 0.6427\n",
      "Epoch 65/150\n",
      "25s - loss: 0.5206 - acc: 0.7795 - val_loss: 0.8793 - val_acc: 0.6320\n",
      "Epoch 66/150\n",
      "24s - loss: 0.5079 - acc: 0.7879 - val_loss: 0.8534 - val_acc: 0.6443\n",
      "Epoch 67/150\n",
      "25s - loss: 0.5016 - acc: 0.7926 - val_loss: 0.8735 - val_acc: 0.6410\n",
      "Epoch 68/150\n",
      "25s - loss: 0.5071 - acc: 0.7912 - val_loss: 0.9195 - val_acc: 0.6307\n",
      "Epoch 69/150\n",
      "25s - loss: 0.4980 - acc: 0.7939 - val_loss: 0.8529 - val_acc: 0.6443\n",
      "Epoch 70/150\n",
      "25s - loss: 0.4931 - acc: 0.7979 - val_loss: 0.8851 - val_acc: 0.6340\n",
      "Epoch 71/150\n",
      "24s - loss: 0.4955 - acc: 0.7904 - val_loss: 0.8599 - val_acc: 0.6433\n",
      "Epoch 72/150\n",
      "25s - loss: 0.4944 - acc: 0.7940 - val_loss: 0.8350 - val_acc: 0.6417\n",
      "Epoch 73/150\n",
      "25s - loss: 0.4855 - acc: 0.7957 - val_loss: 0.9134 - val_acc: 0.6441\n",
      "Epoch 74/150\n",
      "26s - loss: 0.4723 - acc: 0.8082 - val_loss: 0.8977 - val_acc: 0.6303\n",
      "Epoch 75/150\n",
      "30s - loss: 0.4766 - acc: 0.8039 - val_loss: 0.9111 - val_acc: 0.6445\n",
      "Epoch 76/150\n",
      "25s - loss: 0.4675 - acc: 0.8074 - val_loss: 0.9067 - val_acc: 0.6314\n",
      "Epoch 77/150\n",
      "25s - loss: 0.4743 - acc: 0.8068 - val_loss: 0.9086 - val_acc: 0.6318\n",
      "Epoch 78/150\n",
      "24s - loss: 0.4617 - acc: 0.8109 - val_loss: 0.8924 - val_acc: 0.6478\n",
      "Epoch 79/150\n",
      "25s - loss: 0.4617 - acc: 0.8128 - val_loss: 0.8920 - val_acc: 0.6390\n",
      "Epoch 80/150\n",
      "25s - loss: 0.4505 - acc: 0.8204 - val_loss: 0.9083 - val_acc: 0.6367\n",
      "Epoch 81/150\n",
      "25s - loss: 0.4357 - acc: 0.8244 - val_loss: 0.9122 - val_acc: 0.6367\n",
      "Epoch 82/150\n",
      "26s - loss: 0.4535 - acc: 0.8127 - val_loss: 0.9039 - val_acc: 0.6340\n",
      "Epoch 83/150\n",
      "25s - loss: 0.4492 - acc: 0.8137 - val_loss: 0.9057 - val_acc: 0.6404\n",
      "Epoch 84/150\n",
      "24s - loss: 0.4466 - acc: 0.8137 - val_loss: 0.9064 - val_acc: 0.6377\n",
      "Epoch 85/150\n",
      "25s - loss: 0.4468 - acc: 0.8149 - val_loss: 0.8803 - val_acc: 0.6460\n",
      "Epoch 86/150\n",
      "25s - loss: 0.4380 - acc: 0.8206 - val_loss: 0.9287 - val_acc: 0.6458\n",
      "Epoch 87/150\n",
      "26s - loss: 0.4379 - acc: 0.8200 - val_loss: 0.9091 - val_acc: 0.6338\n",
      "Epoch 88/150\n",
      "25s - loss: 0.4189 - acc: 0.8249 - val_loss: 0.9596 - val_acc: 0.6371\n",
      "Epoch 89/150\n",
      "25s - loss: 0.4371 - acc: 0.8267 - val_loss: 0.9133 - val_acc: 0.6462\n",
      "Epoch 90/150\n",
      "25s - loss: 0.4309 - acc: 0.8205 - val_loss: 0.9551 - val_acc: 0.6305\n",
      "Epoch 91/150\n",
      "25s - loss: 0.4151 - acc: 0.8325 - val_loss: 0.8877 - val_acc: 0.6464\n",
      "Epoch 92/150\n",
      "25s - loss: 0.4133 - acc: 0.8312 - val_loss: 0.9379 - val_acc: 0.6371\n",
      "Epoch 93/150\n",
      "24s - loss: 0.4269 - acc: 0.8265 - val_loss: 0.8975 - val_acc: 0.6386\n",
      "Epoch 94/150\n",
      "23s - loss: 0.4092 - acc: 0.8374 - val_loss: 0.9418 - val_acc: 0.6388\n",
      "Epoch 95/150\n",
      "11s - loss: 0.3873 - acc: 0.8450 - val_loss: 0.9603 - val_acc: 0.6421\n",
      "Epoch 96/150\n",
      "11s - loss: 0.3939 - acc: 0.8465 - val_loss: 0.9250 - val_acc: 0.6390\n",
      "Epoch 97/150\n",
      "11s - loss: 0.3894 - acc: 0.8447 - val_loss: 0.9935 - val_acc: 0.6417\n",
      "Epoch 98/150\n",
      "11s - loss: 0.4081 - acc: 0.8322 - val_loss: 0.9100 - val_acc: 0.6386\n",
      "Epoch 99/150\n",
      "11s - loss: 0.4067 - acc: 0.8397 - val_loss: 0.9384 - val_acc: 0.6481\n",
      "Epoch 100/150\n",
      "11s - loss: 0.3783 - acc: 0.8459 - val_loss: 0.9612 - val_acc: 0.6421\n",
      "Epoch 101/150\n",
      "11s - loss: 0.4019 - acc: 0.8419 - val_loss: 0.8686 - val_acc: 0.6431\n",
      "Epoch 102/150\n",
      "11s - loss: 0.4034 - acc: 0.8380 - val_loss: 0.9106 - val_acc: 0.6342\n",
      "Epoch 103/150\n",
      "11s - loss: 0.3679 - acc: 0.8529 - val_loss: 0.9669 - val_acc: 0.6361\n",
      "Epoch 104/150\n",
      "11s - loss: 0.3801 - acc: 0.8450 - val_loss: 0.9272 - val_acc: 0.6450\n",
      "Epoch 105/150\n",
      "11s - loss: 0.3916 - acc: 0.8437 - val_loss: 0.9501 - val_acc: 0.6367\n",
      "Epoch 106/150\n",
      "11s - loss: 0.3763 - acc: 0.8471 - val_loss: 0.9597 - val_acc: 0.6340\n",
      "Epoch 107/150\n",
      "11s - loss: 0.3759 - acc: 0.8502 - val_loss: 0.9345 - val_acc: 0.6390\n",
      "Epoch 108/150\n",
      "11s - loss: 0.3871 - acc: 0.8420 - val_loss: 0.9518 - val_acc: 0.6332\n",
      "Epoch 109/150\n",
      "11s - loss: 0.3620 - acc: 0.8543 - val_loss: 0.9761 - val_acc: 0.6355\n",
      "Epoch 110/150\n",
      "11s - loss: 0.3676 - acc: 0.8536 - val_loss: 0.9780 - val_acc: 0.6349\n",
      "Epoch 111/150\n",
      "11s - loss: 0.3697 - acc: 0.8582 - val_loss: 0.9388 - val_acc: 0.6406\n",
      "Epoch 112/150\n",
      "11s - loss: 0.3805 - acc: 0.8485 - val_loss: 0.9999 - val_acc: 0.6369\n",
      "Epoch 113/150\n",
      "11s - loss: 0.3574 - acc: 0.8588 - val_loss: 0.9618 - val_acc: 0.6472\n",
      "Epoch 114/150\n",
      "11s - loss: 0.3668 - acc: 0.8556 - val_loss: 0.9356 - val_acc: 0.6380\n",
      "Epoch 115/150\n",
      "11s - loss: 0.3758 - acc: 0.8535 - val_loss: 0.9576 - val_acc: 0.6309\n",
      "Epoch 116/150\n",
      "11s - loss: 0.3538 - acc: 0.8606 - val_loss: 1.0047 - val_acc: 0.6419\n",
      "Epoch 117/150\n",
      "11s - loss: 0.3386 - acc: 0.8670 - val_loss: 1.0131 - val_acc: 0.6417\n",
      "Epoch 118/150\n",
      "11s - loss: 0.3528 - acc: 0.8592 - val_loss: 0.9796 - val_acc: 0.6235\n",
      "Epoch 119/150\n",
      "11s - loss: 0.3716 - acc: 0.8533 - val_loss: 0.9413 - val_acc: 0.6390\n",
      "Epoch 120/150\n",
      "11s - loss: 0.3756 - acc: 0.8539 - val_loss: 0.9396 - val_acc: 0.6363\n",
      "Epoch 121/150\n",
      "11s - loss: 0.3639 - acc: 0.8579 - val_loss: 0.9349 - val_acc: 0.6283\n",
      "Epoch 122/150\n",
      "11s - loss: 0.3525 - acc: 0.8632 - val_loss: 0.9624 - val_acc: 0.6429\n",
      "Epoch 123/150\n",
      "11s - loss: 0.3384 - acc: 0.8670 - val_loss: 0.9897 - val_acc: 0.6283\n",
      "Epoch 124/150\n",
      "11s - loss: 0.3271 - acc: 0.8733 - val_loss: 0.9763 - val_acc: 0.6332\n",
      "Epoch 125/150\n",
      "11s - loss: 0.3406 - acc: 0.8649 - val_loss: 0.9690 - val_acc: 0.6340\n",
      "Epoch 126/150\n",
      "11s - loss: 0.3525 - acc: 0.8676 - val_loss: 0.9773 - val_acc: 0.6274\n",
      "Epoch 127/150\n",
      "11s - loss: 0.3545 - acc: 0.8610 - val_loss: 0.9366 - val_acc: 0.6382\n",
      "Epoch 128/150\n",
      "11s - loss: 0.3212 - acc: 0.8750 - val_loss: 0.9830 - val_acc: 0.6382\n",
      "Epoch 129/150\n",
      "11s - loss: 0.3615 - acc: 0.8589 - val_loss: 0.9656 - val_acc: 0.6357\n",
      "Epoch 130/150\n",
      "11s - loss: 0.3438 - acc: 0.8676 - val_loss: 0.9916 - val_acc: 0.6417\n",
      "Epoch 131/150\n",
      "11s - loss: 0.3282 - acc: 0.8702 - val_loss: 1.0387 - val_acc: 0.6394\n",
      "Epoch 132/150\n",
      "11s - loss: 0.3351 - acc: 0.8708 - val_loss: 0.9844 - val_acc: 0.6435\n",
      "Epoch 133/150\n",
      "11s - loss: 0.3246 - acc: 0.8748 - val_loss: 0.9991 - val_acc: 0.6361\n",
      "Epoch 134/150\n",
      "11s - loss: 0.3353 - acc: 0.8738 - val_loss: 0.9725 - val_acc: 0.6396\n",
      "Epoch 135/150\n",
      "11s - loss: 0.3283 - acc: 0.8728 - val_loss: 0.9569 - val_acc: 0.6402\n",
      "Epoch 136/150\n",
      "11s - loss: 0.3298 - acc: 0.8728 - val_loss: 1.0177 - val_acc: 0.6250\n",
      "Epoch 137/150\n",
      "11s - loss: 0.3476 - acc: 0.8681 - val_loss: 0.9632 - val_acc: 0.6340\n",
      "Epoch 138/150\n",
      "11s - loss: 0.3279 - acc: 0.8729 - val_loss: 0.9787 - val_acc: 0.6363\n",
      "Epoch 139/150\n",
      "11s - loss: 0.3223 - acc: 0.8741 - val_loss: 0.9980 - val_acc: 0.6394\n",
      "Epoch 140/150\n",
      "11s - loss: 0.3375 - acc: 0.8702 - val_loss: 0.9388 - val_acc: 0.6423\n",
      "Epoch 141/150\n",
      "11s - loss: 0.3304 - acc: 0.8735 - val_loss: 0.9581 - val_acc: 0.6437\n",
      "Epoch 142/150\n",
      "11s - loss: 0.3294 - acc: 0.8735 - val_loss: 0.9989 - val_acc: 0.6489\n",
      "Epoch 143/150\n",
      "11s - loss: 0.3387 - acc: 0.8666 - val_loss: 0.9906 - val_acc: 0.6423\n",
      "Epoch 144/150\n",
      "12s - loss: 0.3314 - acc: 0.8694 - val_loss: 1.0577 - val_acc: 0.6363\n",
      "Epoch 145/150\n",
      "11s - loss: 0.3341 - acc: 0.8684 - val_loss: 0.9559 - val_acc: 0.6371\n",
      "Epoch 146/150\n",
      "11s - loss: 0.3170 - acc: 0.8733 - val_loss: 0.9778 - val_acc: 0.6415\n",
      "Epoch 147/150\n",
      "11s - loss: 0.3210 - acc: 0.8769 - val_loss: 1.0175 - val_acc: 0.6338\n",
      "Epoch 148/150\n",
      "11s - loss: 0.3298 - acc: 0.8710 - val_loss: 1.0477 - val_acc: 0.6435\n",
      "Epoch 149/150\n",
      "11s - loss: 0.3166 - acc: 0.8767 - val_loss: 1.0480 - val_acc: 0.6402\n",
      "Epoch 150/150\n",
      "11s - loss: 0.3076 - acc: 0.8836 - val_loss: 0.9984 - val_acc: 0.6415\n",
      "test loss: 0.998350292512\n",
      "test accuracy 0.641458891493\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# choose adam as the optimizer\n",
    "# the optmizer chooses the adaptive learnign rates which are used for the Stochastic gradient descent\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "# compile (configure) the model's learning process\n",
    "model.compile(\n",
    "    # choose adam as optimizer\n",
    "    optimizer = adam,\n",
    "    # uses cross entroyphy for loss function\n",
    "    loss='categorical_crossentropy',\n",
    "    # A metric function is similar to an loss function, except that the results from evaluating a metric are not used when training the model.\n",
    "    # https://keras.io/metrics/\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# fit the model with the data to train ig, and data to vlaidate it,\n",
    "# also define the epochs and the batch size for each epochs\n",
    "model.fit(train_data, train_target, validation_data=(val_data, val_target), epochs=150, batch_size=128, verbose=2)\n",
    "# model.fit(train_data, train_target, validation_split=0.3, validation_data=val_data, epochs=50, batch_size=128, verbose=2)\n",
    "# get loss amount and accuracy of the validation set\n",
    "loss, accuracy = model.evaluate(val_data, val_target, verbose=2)\n",
    "print('test loss:', loss)\n",
    "print('test accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# get predictions\n",
    "predictions = model.predict(test_data)\n",
    "# The maximum value along a given axis.\n",
    "# https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.argmax.html\n",
    "output = predictions.argmax(axis=1)\n",
    "# open new file of my choosing\n",
    "f = open('./tanner_summers_hw2_results.csv','w')\n",
    "# Write category header\n",
    "f.write('Id,Category\\n')\n",
    "# loop data and print to file the iteration and it's target for that iteration at i\n",
    "for i in range(0, test_data.shape[0]):\n",
    "    # write data to file\n",
    "    f.write(str(i) + ',' + str(output[i]) + '\\n')\n",
    "# close file\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
