{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# The modules we're going to use\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, convolutional, pooling, Flatten, Dropout\n",
    "from keras.optimizers import Adam,SGD,RMSprop,Adagrad,Adadelta,Adamax,Nadam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# When you execute a code to plot with a simple SHIFT-ENTER, the plot will be shown directly under the code cell\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pre-processing, X_train size:  (16175, 2304)\n",
      "Before pre-processing, y_train size:  (16175,)\n",
      "Before pre-processing, X_test size:  (3965, 2304)\n",
      "After pre-processing, X_train size:  (16175, 1, 48, 48)\n",
      "After pre-processing, y_train size:  (16175, 3)\n",
      "After pre-processing, X_test size:  (3965, 1, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = np.genfromtxt('./train_data.csv',delimiter=',')\n",
    "train_targets = np.genfromtxt('./train_target.csv',delimiter=',')\n",
    "test_data = np.genfromtxt('./test_data.csv',delimiter=',')\n",
    "\n",
    "print('Before pre-processing, X_train size: ', train_data.shape)\n",
    "print('Before pre-processing, y_train size: ', train_targets.shape)\n",
    "print('Before pre-processing, X_test size: ', test_data.shape)\n",
    "\n",
    "train_data = train_data.reshape(-1,1, 48,48)\n",
    "test_data = test_data.reshape(-1,1, 48,48)\n",
    "train_targets = np_utils.to_categorical(train_targets, 3)\n",
    "\n",
    "print('After pre-processing, X_train size: ', train_data.shape)\n",
    "print('After pre-processing, y_train size: ', train_targets.shape)\n",
    "print('After pre-processing, X_test size: ', test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(convolutional.Conv2D(\n",
    "    filters=32,\n",
    "#     use_bias=False,\n",
    "    kernel_size=(2,2),\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    input_shape=(1,48,48),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=32,\n",
    "    padding='same',\n",
    "    strides=(1, 1),\n",
    "    kernel_size=(2,2),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "model.add(pooling.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    padding='same',\n",
    "))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(2,2),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "model.add(convolutional.Conv2D(\n",
    "    filters=64,\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    kernel_size=(2,2),\n",
    "    activation='relu',\n",
    "))\n",
    "\n",
    "model.add(pooling.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    padding='same',\n",
    "))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# model.add(convolutional.Conv2D(\n",
    "#     filters=8,\n",
    "#     kernel_size=(2,2),\n",
    "#     strides=(1, 1),\n",
    "#     padding='same',\n",
    "# #     activation='relu',\n",
    "# ))\n",
    "\n",
    "# model.add(convolutional.Conv2D(\n",
    "#     filters=8,\n",
    "#     kernel_size=(2,2),\n",
    "#     strides=(1, 1),\n",
    "#     padding='same',\n",
    "# #     activation='relu',\n",
    "# ))\n",
    "\n",
    "# model.add(pooling.MaxPooling2D(\n",
    "#     pool_size=(2, 2),\n",
    "#     padding='same',\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# model.add(Dense(1026))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(drop_out_rate))\n",
    "\n",
    "\n",
    "# # model.add(Dense(1026))\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(Dropout(drop_out_rate))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11322 samples, validate on 4853 samples\n",
      "Epoch 1/50\n",
      "8s - loss: 1.9047 - acc: 0.4034 - val_loss: 1.0603 - val_acc: 0.4478\n",
      "Epoch 2/50\n",
      "9s - loss: 1.0675 - acc: 0.4406 - val_loss: 1.0638 - val_acc: 0.4517\n",
      "Epoch 3/50\n",
      "6s - loss: 1.0634 - acc: 0.4362 - val_loss: 1.0500 - val_acc: 0.4492\n",
      "Epoch 4/50\n",
      "4s - loss: 1.0534 - acc: 0.4489 - val_loss: 1.0452 - val_acc: 0.4544\n",
      "Epoch 5/50\n",
      "6s - loss: 1.0459 - acc: 0.4595 - val_loss: 1.0493 - val_acc: 0.4597\n",
      "Epoch 6/50\n",
      "6s - loss: 1.0352 - acc: 0.4664 - val_loss: 1.0352 - val_acc: 0.4871\n",
      "Epoch 7/50\n",
      "10s - loss: 1.0252 - acc: 0.4845 - val_loss: 1.0169 - val_acc: 0.5020\n",
      "Epoch 8/50\n",
      "7s - loss: 1.0119 - acc: 0.4988 - val_loss: 1.0120 - val_acc: 0.4978\n",
      "Epoch 9/50\n",
      "5s - loss: 1.0045 - acc: 0.5010 - val_loss: 1.0034 - val_acc: 0.5086\n",
      "Epoch 10/50\n",
      "4s - loss: 0.9962 - acc: 0.5123 - val_loss: 0.9716 - val_acc: 0.5294\n",
      "Epoch 11/50\n",
      "5s - loss: 0.9871 - acc: 0.5145 - val_loss: 0.9576 - val_acc: 0.5411\n",
      "Epoch 12/50\n",
      "5s - loss: 0.9688 - acc: 0.5335 - val_loss: 0.9600 - val_acc: 0.5353\n",
      "Epoch 13/50\n",
      "6s - loss: 0.9568 - acc: 0.5367 - val_loss: 0.9348 - val_acc: 0.5535\n",
      "Epoch 14/50\n",
      "6s - loss: 0.9451 - acc: 0.5474 - val_loss: 0.9308 - val_acc: 0.5473\n",
      "Epoch 15/50\n",
      "7s - loss: 0.9448 - acc: 0.5495 - val_loss: 0.9380 - val_acc: 0.5436\n",
      "Epoch 16/50\n",
      "8s - loss: 0.9383 - acc: 0.5536 - val_loss: 0.9223 - val_acc: 0.5533\n",
      "Epoch 17/50\n",
      "4s - loss: 0.9264 - acc: 0.5594 - val_loss: 0.9072 - val_acc: 0.5673\n",
      "Epoch 18/50\n",
      "4s - loss: 0.9240 - acc: 0.5568 - val_loss: 0.9092 - val_acc: 0.5739\n",
      "Epoch 19/50\n",
      "4s - loss: 0.9087 - acc: 0.5703 - val_loss: 0.9060 - val_acc: 0.5667\n",
      "Epoch 20/50\n",
      "4s - loss: 0.9096 - acc: 0.5701 - val_loss: 0.8943 - val_acc: 0.5730\n",
      "Epoch 21/50\n",
      "4s - loss: 0.8959 - acc: 0.5772 - val_loss: 0.8985 - val_acc: 0.5858\n",
      "Epoch 22/50\n",
      "4s - loss: 0.8874 - acc: 0.5860 - val_loss: 0.8902 - val_acc: 0.5858\n",
      "Epoch 23/50\n",
      "4s - loss: 0.8863 - acc: 0.5829 - val_loss: 0.8887 - val_acc: 0.5897\n",
      "Epoch 24/50\n",
      "4s - loss: 0.8791 - acc: 0.5897 - val_loss: 0.8907 - val_acc: 0.5813\n",
      "Epoch 25/50\n",
      "6s - loss: 0.8736 - acc: 0.5931 - val_loss: 0.8859 - val_acc: 0.5840\n",
      "Epoch 26/50\n",
      "8s - loss: 0.8686 - acc: 0.5965 - val_loss: 0.8771 - val_acc: 0.5883\n",
      "Epoch 27/50\n",
      "12s - loss: 0.8602 - acc: 0.6020 - val_loss: 0.8809 - val_acc: 0.5899\n",
      "Epoch 28/50\n",
      "10s - loss: 0.8587 - acc: 0.6019 - val_loss: 0.8796 - val_acc: 0.5887\n",
      "Epoch 29/50\n",
      "10s - loss: 0.8491 - acc: 0.6087 - val_loss: 0.8654 - val_acc: 0.5974\n",
      "Epoch 30/50\n",
      "14s - loss: 0.8457 - acc: 0.6105 - val_loss: 0.8710 - val_acc: 0.5945\n",
      "Epoch 31/50\n",
      "13s - loss: 0.8340 - acc: 0.6159 - val_loss: 0.8604 - val_acc: 0.6079\n",
      "Epoch 32/50\n",
      "13s - loss: 0.8311 - acc: 0.6199 - val_loss: 0.8845 - val_acc: 0.5866\n",
      "Epoch 33/50\n",
      "15s - loss: 0.8236 - acc: 0.6253 - val_loss: 0.8651 - val_acc: 0.5887\n",
      "Epoch 34/50\n",
      "14s - loss: 0.8114 - acc: 0.6305 - val_loss: 0.8669 - val_acc: 0.5943\n",
      "Epoch 35/50\n",
      "11s - loss: 0.8110 - acc: 0.6282 - val_loss: 0.8635 - val_acc: 0.5970\n",
      "Epoch 36/50\n",
      "14s - loss: 0.8178 - acc: 0.6267 - val_loss: 0.8777 - val_acc: 0.5928\n",
      "Epoch 37/50\n",
      "15s - loss: 0.8098 - acc: 0.6347 - val_loss: 0.8776 - val_acc: 0.5866\n",
      "Epoch 38/50\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "sgd = SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "rms_prop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "adadelta = Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "adamax = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "nadam = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    # optimizer = adam,\n",
    "    optimizer = 'adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# model.fit(train_data, train_targets,epochs=10,batch_size=32,verbose=2)\n",
    "model.fit(train_data, train_targets, validation_split=0.30, epochs=50, batch_size=128, verbose=2)\n",
    "\n",
    "# loss, accuracy = model.evaluate(test_data, test_target, verbose=2)\n",
    "# print('test loss:', loss)\n",
    "# print('test accuracy', accuracy)\n",
    "\n",
    "\n",
    "# output = model.predict(X_test[temp[0]].reshape(-1,1, 28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the prediction\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "output = predictions.argmax(axis=1)\n",
    "\n",
    "f = open('./result3.csv','w')\n",
    "f.write('Id,Category\\n') #Give your csv text here.\n",
    "for i in range(0, test_data.shape[0]):\n",
    "    f.write(str(i) + ',' + str(output[i]) + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
